# -*- coding: utf-8 -*-
"""CI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MvK9byEYhh3olSnclyyweXu9LDbahGY7
"""

! rm -rf ""

!pip install obonet
!pip install pyvis

import re
def get_embeddings(seq):
    sequence_examples = [" ".join(list(re.sub(r"[UZOB]", "X", seq)))]

    ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding="longest")

    input_ids = torch.tensor(ids['input_ids']).to(device)
    attention_mask = torch.tensor(ids['attention_mask']).to(device)

    # generate embeddings
    with torch.no_grad():
        embedding_repr = model(input_ids=input_ids,
                               attention_mask=attention_mask)

    # extract residue embeddings for the first ([0,:]) sequence in the batch and remove padded & special tokens ([0,:7])
    emb_0 = embedding_repr.last_hidden_state[0]
    emb_0_per_protein = emb_0.mean(dim=0)

    return emb_0_per_protein

import os
import json
from typing import Dict
from collections import Counter

import random
import obonet
import pandas as pd
import numpy as np
from Bio import SeqIO

from transformers import T5Tokenizer, T5EncoderModel
import torch
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Load the tokenizer
tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False) #.to(device)

# Load the model
model = T5EncoderModel.from_pretrained("Rostlab/prot_t5_xl_half_uniref50-enc").to(device);

# only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)
#model.full() if device=='cpu' else model.half()



! pip install Bio

predictions= [[1 for i in range(1024)]]
a=pd.DataFrame(predictions)
a.to_csv("/content/input.csv")

import tqdm
from Bio import SeqIO
import numpy as np
import pandas as pd
import tensorflow as tf

def predict(filepath):

    fn = filepath

    sequences = SeqIO.parse(fn, "fasta")

    ids = []
    num_sequences=sum(1 for seq in sequences)
    embeds = np.zeros((num_sequences, 1024))
    i = 0
    for seq in tqdm.tqdm(sequences):
        ids.append(seq.id)
        embeds[i] = get_embeddings(str(seq.seq)).detach().cpu().numpy()
        i += 1
        # if i==10:
        #     break #remove it for full calculation

    # np.save('train_embeds.npy', embeds)
    # np.save('train_ids.npy', np.array(ids))
    # batch_shape=5120
    INPUT_SHAPE=[1024]
    num_of_labels=1500
    # from tf.keras.models import load_model
    model = tf.keras.Sequential([
        tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),
        tf.keras.layers.Dense(units=512, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=512, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=512, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['binary_accuracy', tf.keras.metrics.AUC()]
    )
    model.load_weights('/content/drive/MyDrive/my_model.weights.h5') #load model here
    labels_df=pd.read_csv('/content/truncated.csv')
    labels_df=labels_df.drop(columns='Unnamed: 0')
#     custom_input_tensor = np.load("/kaggle/input/t5embeds/test_embeds.npy") # add the numpy array here
    custom_input_tensor=embeds
    # custom_input_tensor=np.zeros((3, 1024))
    print(custom_input_tensor)
    print(len(custom_input_tensor[0]))
    # Get predictions for custom input tensor
    predictions = model.predict(custom_input_tensor)
    predictions_list=[]
    # 'predictions' will contain the model's output for the custom input tensor
    # print(predictions)
    for prediction in predictions:
        tmp=[]
        for i in prediction:
            x=0 if i<0.5 else 1
            tmp.append(x)
        predictions_list.append(tmp.copy())
        # print(sum(tmp))
        print(prediction)
    # print(len(predictions))

    # labels_df=
    # Get the column names (labels) from the original DataFrame
    label_columns = labels_df.columns

    # Convert the predictions into a DataFrame
    predictions_df = pd.DataFrame(predictions_list, columns=label_columns)

    # Save the DataFrame to a CSV file
    predictions_df.to_csv("custom_predictions.csv", index=False) #output csv
    return "custom_predictions.csv"

!pip install -q gradio

a=predict("/content/abc.fasta")
print(a)

# batch_shape=5120
import tensorflow as tf
import numpy as np
import pandas as pd

INPUT_SHAPE=[1024]
num_of_labels=1500
# from tf.keras.models import load_model
model = tf.keras.Sequential([
    tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),
    tf.keras.layers.Dense(units=512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(units=512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(units=512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['binary_accuracy', tf.keras.metrics.AUC()]
)
model.load_weights('/content/drive/MyDrive/my_model.weights.h5')

# model=tf.keras.models.load_model("/content/drive/MyDrive/model1.h5") #load model here
labels_df=pd.read_csv('/content/truncated.csv')
labels_df=labels_df.drop(columns='Unnamed: 0')
#     custom_input_tensor = np.load("/kaggle/input/t5embeds/test_embeds.npy") # add the numpy array here
# custom_input_tensor=embeds
custom_input_tensor=np.random.random((100, 1024))
print(custom_input_tensor)
print(len(custom_input_tensor[0]))
# Get predictions for custom input tensor
predictions = model.predict(custom_input_tensor)
predictions_list=[]
# 'predictions' will contain the model's output for the custom input tensor
# print(predictions)
cnt=0
for prediction in predictions:
    tmp=[]
    for i in prediction:
        x=0 if i<0.5 else 1
        tmp.append(x)
    predictions_list.append(tmp.copy())
    # print(sum(tmp))
    cnt+=sum(tmp)
    # print(tmp)
    print(sum(tmp))
print(cnt)
# print(len(predictions))

# labels_df=
# Get the column names (labels) from the original DataFrame
label_columns = labels_df.columns

# Convert the predictions into a DataFrame
predictions_df = pd.DataFrame(predictions_list, columns=label_columns)

# Save the DataFrame to a CSV file
predictions_df.to_csv("custom_predictions.csv", index=False) #output csv

import gradio as gr
import pandas as pd

import gradio as gr
gr.Interface(
    predict,
    title = 'Protein Function Prediction using fasta file,upload a fasta file',
    inputs="file",
    outputs="file"
).launch(share=True,debug=True)