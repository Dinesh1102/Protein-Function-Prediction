{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4JkM3wkNDAZa"
      },
      "outputs": [],
      "source": [
        "! rm -rf \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install obonet\n",
        "!pip install pyvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crz67h5lH_Nd",
        "outputId": "22cf1a85-96fc-4fb4-a80d-ff2ec4298655"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obonet in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from obonet) (3.2.1)\n",
            "Requirement already satisfied: pyvis in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.3)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.0.3)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def get_embeddings(seq):\n",
        "    sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq)))]\n",
        "\n",
        "    ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
        "\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    # generate embeddings\n",
        "    with torch.no_grad():\n",
        "        embedding_repr = model(input_ids=input_ids,\n",
        "                               attention_mask=attention_mask)\n",
        "\n",
        "    # extract residue embeddings for the first ([0,:]) sequence in the batch and remove padded & special tokens ([0,:7])\n",
        "    emb_0 = embedding_repr.last_hidden_state[0]\n",
        "    emb_0_per_protein = emb_0.mean(dim=0)\n",
        "\n",
        "    return emb_0_per_protein"
      ],
      "metadata": {
        "id": "UPJLzMVjDFsB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from typing import Dict\n",
        "from collections import Counter\n",
        "\n",
        "import random\n",
        "import obonet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from Bio import SeqIO\n",
        "\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False) #.to(device)\n",
        "\n",
        "# Load the model\n",
        "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device);\n",
        "\n",
        "# only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)\n",
        "#model.full() if device=='cpu' elseÂ model.half()"
      ],
      "metadata": {
        "id": "LV0t3WgtDFuC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0gJ_bocNDFv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install Bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCmpy47wDFyL",
        "outputId": "8d4fc3ce-2dfc-4ac6-9282-3c192821834a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Bio in /usr/local/lib/python3.10/dist-packages (1.6.2)\n",
            "Requirement already satisfied: biopython>=1.80 in /usr/local/lib/python3.10/dist-packages (from Bio) (1.83)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.2)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.10/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (2.0.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.8.1)\n",
            "Requirement already satisfied: gprofiler-official in /usr/local/lib/python3.10/dist-packages (from Bio) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.25.2)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from mygene->Bio) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2024.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions= [[1 for i in range(1024)]]\n",
        "a=pd.DataFrame(predictions)\n",
        "a.to_csv(\"/content/input.csv\")"
      ],
      "metadata": {
        "id": "HcbkBl5ANVjs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict(filepath):\n",
        "\n",
        "    fn = filepath\n",
        "\n",
        "    sequences = SeqIO.parse(fn, \"fasta\")\n",
        "\n",
        "    ids = []\n",
        "    num_sequences=sum(1 for seq in sequences)\n",
        "    embeds = np.zeros((num_sequences, 1024))\n",
        "    i = 0\n",
        "    for seq in tqdm.tqdm(sequences):\n",
        "        ids.append(seq.id)\n",
        "        embeds[i] = get_embeddings(str(seq.seq)).detach().cpu().numpy()\n",
        "        i += 1\n",
        "        # if i==10:\n",
        "        #     break #remove it for full calculation\n",
        "\n",
        "    # np.save('train_embeds.npy', embeds)\n",
        "    # np.save('train_ids.npy',Â np.array(ids))\n",
        "    # batch_shape=5120\n",
        "    INPUT_SHAPE=[1024]\n",
        "    num_of_labels=1500\n",
        "    # from tf.keras.models import load_model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),\n",
        "        tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['binary_accuracy', tf.keras.metrics.AUC()]\n",
        "    )\n",
        "    model.load_weights('/content/drive/MyDrive/my_model.weights.h5') #load model here\n",
        "    labels_df=pd.read_csv('/content/truncated.csv')\n",
        "    labels_df=labels_df.drop(columns='Unnamed: 0')\n",
        "#     custom_input_tensor = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\") # add the numpy array here\n",
        "    custom_input_tensor=embeds\n",
        "    # custom_input_tensor=np.zeros((3, 1024))\n",
        "    print(custom_input_tensor)\n",
        "    print(len(custom_input_tensor[0]))\n",
        "    # Get predictions for custom input tensor\n",
        "    predictions = model.predict(custom_input_tensor)\n",
        "    predictions_list=[]\n",
        "    # 'predictions' will contain the model's output for the custom input tensor\n",
        "    # print(predictions)\n",
        "    for prediction in predictions:\n",
        "        tmp=[]\n",
        "        for i in prediction:\n",
        "            x=0 if i<0.5 else 1\n",
        "            tmp.append(x)\n",
        "        predictions_list.append(tmp.copy())\n",
        "        # print(sum(tmp))\n",
        "        print(prediction)\n",
        "    # print(len(predictions))\n",
        "\n",
        "    # labels_df=\n",
        "    # Get the column names (labels) from the original DataFrame\n",
        "    label_columns = labels_df.columns\n",
        "\n",
        "    # Convert the predictions into a DataFrame\n",
        "    predictions_df = pd.DataFrame(predictions_list, columns=label_columns)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    predictions_df.to_csv(\"custom_predictions.csv\", index=False) #output csv\n",
        "    return \"custom_predictions.csv\"\n"
      ],
      "metadata": {
        "id": "Elgwoko_DF0S"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "XVNpuxo5DF16"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=predict(\"/content/abc.fasta\")\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VM8qC2mDF5f",
        "outputId": "2580257a-eff4-41c7-e05b-5f184b2d8e8f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "1024\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "1\n",
            "custom_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_shape=5120\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "INPUT_SHAPE=[1024]\n",
        "num_of_labels=1500\n",
        "# from tf.keras.models import load_model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy', tf.keras.metrics.AUC()]\n",
        ")\n",
        "model.load_weights('/content/drive/MyDrive/my_model.weights.h5')\n",
        "\n",
        "# model=tf.keras.models.load_model(\"/content/drive/MyDrive/model1.h5\") #load model here\n",
        "labels_df=pd.read_csv('/content/truncated.csv')\n",
        "labels_df=labels_df.drop(columns='Unnamed: 0')\n",
        "#     custom_input_tensor = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\") # add the numpy array here\n",
        "# custom_input_tensor=embeds\n",
        "custom_input_tensor=np.random.random((100, 1024))\n",
        "print(custom_input_tensor)\n",
        "print(len(custom_input_tensor[0]))\n",
        "# Get predictions for custom input tensor\n",
        "predictions = model.predict(custom_input_tensor)\n",
        "predictions_list=[]\n",
        "# 'predictions' will contain the model's output for the custom input tensor\n",
        "# print(predictions)\n",
        "cnt=0\n",
        "for prediction in predictions:\n",
        "    tmp=[]\n",
        "    for i in prediction:\n",
        "        x=0 if i<0.5 else 1\n",
        "        tmp.append(x)\n",
        "    predictions_list.append(tmp.copy())\n",
        "    # print(sum(tmp))\n",
        "    cnt+=sum(tmp)\n",
        "    # print(tmp)\n",
        "    print(sum(tmp))\n",
        "print(cnt)\n",
        "# print(len(predictions))\n",
        "\n",
        "# labels_df=\n",
        "# Get the column names (labels) from the original DataFrame\n",
        "label_columns = labels_df.columns\n",
        "\n",
        "# Convert the predictions into a DataFrame\n",
        "predictions_df = pd.DataFrame(predictions_list, columns=label_columns)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "predictions_df.to_csv(\"custom_predictions.csv\", index=False) #output csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8akdoZUSQQBf",
        "outputId": "ec958a28-3fcf-4b5f-e933-6d8ce8b3aae1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.04404056 0.08912223 0.26120968 ... 0.62678027 0.82235433 0.3202845 ]\n",
            " [0.24504959 0.87050151 0.282636   ... 0.26825446 0.96879317 0.17777832]\n",
            " [0.85421075 0.66590741 0.5749779  ... 0.89506666 0.54754993 0.03731561]\n",
            " ...\n",
            " [0.13289982 0.87559716 0.3199096  ... 0.1790593  0.97360167 0.22326068]\n",
            " [0.40723982 0.82847947 0.46348826 ... 0.52270772 0.90143254 0.35830025]\n",
            " [0.04749935 0.42091512 0.91150753 ... 0.15370932 0.68776259 0.81459474]]\n",
            "1024\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "7\n",
            "4\n",
            "4\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "7\n",
            "3\n",
            "4\n",
            "3\n",
            "5\n",
            "4\n",
            "4\n",
            "3\n",
            "7\n",
            "2\n",
            "4\n",
            "3\n",
            "9\n",
            "8\n",
            "6\n",
            "5\n",
            "4\n",
            "7\n",
            "3\n",
            "4\n",
            "3\n",
            "5\n",
            "4\n",
            "1\n",
            "4\n",
            "5\n",
            "4\n",
            "2\n",
            "3\n",
            "4\n",
            "8\n",
            "4\n",
            "3\n",
            "3\n",
            "8\n",
            "7\n",
            "5\n",
            "4\n",
            "5\n",
            "3\n",
            "3\n",
            "4\n",
            "5\n",
            "2\n",
            "8\n",
            "4\n",
            "5\n",
            "5\n",
            "2\n",
            "3\n",
            "2\n",
            "6\n",
            "5\n",
            "7\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "4\n",
            "5\n",
            "3\n",
            "3\n",
            "5\n",
            "2\n",
            "4\n",
            "3\n",
            "5\n",
            "5\n",
            "4\n",
            "2\n",
            "3\n",
            "1\n",
            "12\n",
            "4\n",
            "7\n",
            "9\n",
            "2\n",
            "5\n",
            "7\n",
            "6\n",
            "4\n",
            "6\n",
            "4\n",
            "2\n",
            "4\n",
            "5\n",
            "5\n",
            "3\n",
            "2\n",
            "6\n",
            "3\n",
            "4\n",
            "4\n",
            "441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "sGK26AWcD9ET"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "gr.Interface(\n",
        "    predict,\n",
        "    title = 'Protein Function Prediction using fasta file,upload a fasta file',\n",
        "    inputs=\"file\",\n",
        "    outputs=\"file\"\n",
        ").launch(share=True,debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "13FQgINnGx8H",
        "outputId": "2eed0cb0-227f-49b6-9ff6-4ff5450793f1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://f0948d36ed720d5ae5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f0948d36ed720d5ae5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "1024\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "[0.4348464  0.53423107 0.42620808 ... 0.08446681 0.08856744 0.14838184]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d8b932897f950af0db.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://d0b2de10a3ab82e50e.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://5541d58b12b1a61bc0.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://b3dbaf6fd558c49a43.gradio.live\n",
            "Killing tunnel 127.0.0.1:7864 <> https://5c3a55f6a215182ca7.gradio.live\n",
            "Killing tunnel 127.0.0.1:7865 <> https://af815fe6c84532cecb.gradio.live\n",
            "Killing tunnel 127.0.0.1:7866 <> https://f0948d36ed720d5ae5.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}